{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import tkinter as tk\n",
    "import xml.etree.ElementTree as ET\n",
    "from tkinter import filedialog\n",
    "\n",
    "def setup_database(db_path):\n",
    "    \"\"\"Create Power_Analysis database and table if it doesn’t exist\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    conn.execute(\"PRAGMA busy_timeout=5000;\")\n",
    "\n",
    "    power_data_schema = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Power_Analysis (\n",
    "        ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        pitch_id TEXT,\n",
    "        Name TEXT,\n",
    "        Date_of_Birth TEXT,\n",
    "        Height REAL,\n",
    "        Weight REAL,\n",
    "        Filename TEXT,\n",
    "        Comments TEXT,\n",
    "        Creation_Date TEXT,\n",
    "        PowerALL_X REAL,\n",
    "        PowerALL_Y REAL,\n",
    "        PowerALL_Z REAL,\n",
    "        PowerMAG REAL,\n",
    "        Center_of_Mass_Vel2_X REAL,\n",
    "        Center_of_Mass_Vel2_Y REAL,\n",
    "        Center_of_Mass_Vel2_Z REAL,\n",
    "        Foot_Contact REAL,\n",
    "        Release REAL,\n",
    "        Release100ms REAL\n",
    "    );\n",
    "    \"\"\"\n",
    "    cursor.execute(power_data_schema)\n",
    "    conn.commit()\n",
    "    return conn, cursor\n",
    "\n",
    "# --- 1. Folder select\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "selected_folder = filedialog.askdirectory(initialdir='./')\n",
    "if not selected_folder:\n",
    "    print(\"No folder selected. Exiting...\")\n",
    "    exit()\n",
    "\n",
    "db_path = os.path.join(selected_folder, \"Power_Analysis.db\")\n",
    "conn, cursor = setup_database(db_path)\n",
    "\n",
    "# --- 2. Find and parse XML\n",
    "xml_file_path = ''\n",
    "for root_dir, _, files in os.walk(selected_folder):\n",
    "    for file in files:\n",
    "        if file.lower() == 'session.xml':\n",
    "            xml_file_path = os.path.join(root_dir, file)\n",
    "            break\n",
    "    if xml_file_path:\n",
    "        break\n",
    "\n",
    "if not xml_file_path:\n",
    "    print(\"No session.xml found. Exiting...\")\n",
    "    conn.close()\n",
    "    exit()\n",
    "\n",
    "tree = ET.parse(xml_file_path)\n",
    "xml_root = tree.getroot()\n",
    "\n",
    "def find_text(element, tag):\n",
    "    found = element.find(tag)\n",
    "    return found.text if found is not None else None\n",
    "\n",
    "subject = xml_root\n",
    "subject_fields = subject.find(\"Fields\")\n",
    "name = find_text(subject_fields, \"Name\")\n",
    "date_of_birth = find_text(subject_fields, \"Date_of_birth\")\n",
    "height = find_text(subject_fields, \"Height\")\n",
    "weight = find_text(subject_fields, \"Weight\")\n",
    "creation_date = find_text(subject_fields, \"Creation_date\")\n",
    "\n",
    "# --- 3. Get measurement info but don’t insert yet\n",
    "measurements = []\n",
    "for measurement in xml_root.findall(\".//Measurement[@Type='Fastball RH']\"):\n",
    "    fields = measurement.find(\"Fields\")\n",
    "    if fields is None:\n",
    "        continue\n",
    "    used = find_text(fields, \"Used\")\n",
    "    if used and used.lower() == 'true':\n",
    "        filename = measurement.get(\"Filename\")\n",
    "        comments = find_text(fields, \"Comments\")\n",
    "        measurement_creation_date = find_text(fields, \"Creation_date\") or creation_date\n",
    "        measurements.append((filename, comments, measurement_creation_date))\n",
    "\n",
    "if not measurements:\n",
    "    print(\"No used Fastball RH found — pulling all Fastball RH instead.\")\n",
    "    for measurement in xml_root.findall(\".//Measurement[@Type='Fastball RH']\"):\n",
    "        fields = measurement.find(\"Fields\")\n",
    "        if fields is None:\n",
    "            continue\n",
    "        filename = measurement.get(\"Filename\")\n",
    "        comments = find_text(fields, \"Comments\")\n",
    "        measurement_creation_date = find_text(fields, \"Creation_date\") or creation_date\n",
    "        measurements.append((filename, comments, measurement_creation_date))\n",
    "\n",
    "print(f\"Subject: {name}, DOB: {date_of_birth}, Height: {height}, Weight: {weight}\")\n",
    "print(f\"Found {len(measurements)} Fastball RH measurements\")\n",
    "\n",
    "# --- 4. Store for next cell (global vars)\n",
    "subject_info = {\n",
    "    \"name\": name,\n",
    "    \"dob\": date_of_birth,\n",
    "    \"height\": height,\n",
    "    \"weight\": weight,\n",
    "    \"creation_date\": creation_date\n",
    "}\n",
    "measurement_info = measurements\n",
    "\n",
    "conn.close()\n",
    "print(\"\\nDatabase structure ready — demographics and filenames loaded.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import re\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import inf\n",
    "from scipy import stats\n",
    "\n",
    "class PowerAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.folder_path = None\n",
    "        self.db_path = None\n",
    "        self.conn = None\n",
    "        self.cursor = None\n",
    "        \n",
    "    def select_folder(self):\n",
    "        \"\"\"Use tkinter to select a folder containing power files\"\"\"\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()  # Hide the main window\n",
    "        \n",
    "        folder_path = filedialog.askdirectory(\n",
    "            title=\"Select folder containing power files\"\n",
    "        )\n",
    "        \n",
    "        if folder_path:\n",
    "            self.folder_path = folder_path\n",
    "            self.db_path = os.path.join(folder_path, \"power_analysis.db\")\n",
    "            print(f\"Selected folder: {self.folder_path}\")\n",
    "            return True\n",
    "        else:\n",
    "            messagebox.showwarning(\"No Selection\", \"No folder selected. Exiting.\")\n",
    "            return False\n",
    "    \n",
    "    def connect_to_existing_db(self):\n",
    "        \"\"\"Connect to Power_Analysis.db to make one combined Power_Analysis table\"\"\"\n",
    "        \n",
    "        if not self.folder_path:\n",
    "            raise ValueError(\"No folder path set. Select folder before connecting to database.\")\n",
    "\n",
    "        self.db_path = os.path.join(self.folder_path, \"Power_Analysis.db\")\n",
    "        self.conn = sqlite3.connect(self.db_path)\n",
    "        self.cursor = self.conn.cursor()\n",
    "        self.conn.execute(\"PRAGMA busy_timeout=5000;\")\n",
    "\n",
    "        # Combined table with demographics and power data\n",
    "        self.cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS Power_Analysis (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                Name TEXT,\n",
    "                Date_of_Birth TEXT,\n",
    "                Height REAL,\n",
    "                Weight REAL,\n",
    "                Filename TEXT,\n",
    "                Comments TEXT,\n",
    "                Creation_Date TEXT,\n",
    "                pitch_id INTEGER,\n",
    "                PowerALL_X REAL,\n",
    "                PowerALL_Y REAL,\n",
    "                PowerALL_Z REAL,\n",
    "                PowerMAG REAL,\n",
    "                Foot_Contact REAL,\n",
    "                Release REAL,\n",
    "                Release100ms REAL,\n",
    "                Center_of_Mass_Vel2_X REAL,\n",
    "                Center_of_Mass_Vel2_Y REAL,\n",
    "                Center_of_Mass_Vel2_Z REAL,\n",
    "                pelvis_peak_power REAL,\n",
    "                pelvis_time_to_peak REAL,\n",
    "                pelvis_auc REAL,\n",
    "                shoulder_peak_power REAL,\n",
    "                shoulder_time_to_peak REAL,\n",
    "                shoulder_auc REAL,\n",
    "                elbow_peak_power REAL,\n",
    "                elbow_time_to_peak REAL,\n",
    "                elbow_auc REAL,\n",
    "                power_curve_peak_power REAL,\n",
    "                power_curve_time_to_peak REAL,\n",
    "                power_curve_auc REAL,\n",
    "                fs1_peak_power REAL,\n",
    "                fs1_time_to_peak REAL,\n",
    "                fs1_auc REAL\n",
    "            );\n",
    "        \"\"\")\n",
    "\n",
    "        required_columns = [\n",
    "            \"pitch_id\", \n",
    "            \"PowerALL_X\", \"PowerALL_Y\", \"PowerALL_Z\",\n",
    "            \"Center_of_Mass_Vel2_X\", \"Center_of_Mass_Vel2_Y\", \"Center_of_Mass_Vel2_Z\",\n",
    "            \"PowerMAG\", \"Foot_Contact\", \"Release\", \"Release100ms\",\n",
    "            \"pelvis_peak_power\", \"pelvis_time_to_peak\", \"pelvis_auc\",\n",
    "            \"shoulder_peak_power\", \"shoulder_time_to_peak\", \"shoulder_auc\",\n",
    "            \"elbow_peak_power\", \"elbow_time_to_peak\", \"elbow_auc\",\n",
    "            \"power_curve_peak_power\", \"power_curve_time_to_peak\", \"power_curve_auc\",\n",
    "            \"fs1_peak_power\", \"fs1_time_to_peak\", \"fs1_auc\"\n",
    "        ]\n",
    "\n",
    "        self.cursor.execute(\"PRAGMA table_info(Power_Analysis);\")\n",
    "        existing_columns = [col[1] for col in self.cursor.fetchall()]\n",
    "\n",
    "        # Add any missing ones\n",
    "        for col in required_columns:\n",
    "            if col not in existing_columns:\n",
    "                self.cursor.execute(f\"ALTER TABLE Power_Analysis ADD COLUMN {col} REAL;\")\n",
    "                print(f\"Added missing column: {col}\")\n",
    "\n",
    "        self.conn.commit()\n",
    "        print(\"Connected to Power_Analysis.db (non-destructive) and ensured all columns exist.\")\n",
    "    \n",
    "    def setup_database(db_path):\n",
    "        \"\"\"Create a single Power_Analysis table with demographics + power data.\"\"\"\n",
    "        if os.path.exists(db_path):\n",
    "            os.remove(db_path)\n",
    "            print(f\"Deleted existing database at {db_path}\")\n",
    "    \n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        conn.execute(\"PRAGMA busy_timeout=5000;\")\n",
    "    \n",
    "        cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS Power_Analysis (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            Name TEXT,\n",
    "            Date_of_Birth TEXT,\n",
    "            Height REAL,\n",
    "            Weight REAL,\n",
    "            Filename TEXT,\n",
    "            Comments TEXT,\n",
    "            Creation_Date TEXT,\n",
    "\n",
    "            -- pitch data\n",
    "            pitch_id INTEGER,\n",
    "            PowerALL_X REAL,\n",
    "            PowerALL_Y REAL,\n",
    "            PowerALL_Z REAL,\n",
    "            PowerMAG REAL,\n",
    "            Center_of_Mass_Vel2_X REAL,\n",
    "            Center_of_Mass_Vel2_Y REAL,\n",
    "            Center_of_Mass_Vel2_Z REAL,\n",
    "            Foot_Contact REAL,\n",
    "            Release REAL,\n",
    "            Release100ms REAL,\n",
    "\n",
    "            -- power metrics\n",
    "            pelvis_peak_power REAL,\n",
    "            pelvis_time_to_peak REAL,\n",
    "            pelvis_auc REAL,\n",
    "            shoulder_peak_power REAL,\n",
    "            shoulder_time_to_peak REAL,\n",
    "            shoulder_auc REAL,\n",
    "            elbow_peak_power REAL,\n",
    "            elbow_time_to_peak REAL,\n",
    "            elbow_auc REAL,\n",
    "            power_curve_peak_power REAL,\n",
    "            power_curve_time_to_peak REAL,\n",
    "            power_curve_auc REAL,\n",
    "            fs1_peak_power REAL,\n",
    "            fs1_time_to_peak REAL,\n",
    "            fs1_auc REAL\n",
    "        );\n",
    "        \"\"\")\n",
    "    \n",
    "        conn.commit()\n",
    "        print(\"Power_Analysis table created successfully.\")\n",
    "        return conn, cursor\n",
    "\n",
    "\n",
    "    def extract_filename(self, line):\n",
    "        \"\"\"Extract filename from data line\"\"\"\n",
    "        filename = os.path.splitext(os.path.basename(line))[0]\n",
    "        return filename\n",
    "\n",
    "    def extract_pitch_id(self, filename):\n",
    "        match = re.search(r'(?:LH|RH)\\s*(\\d+)', filename)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        return None\n",
    "    \n",
    "    def read_first_numeric_row_values(self, fobj):\n",
    "        \"\"\"Return list of floats from the first numeric line encountered.\"\"\"\n",
    "        for line in fobj:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if re.match(r'^[-+]?\\d', line):   # numeric line\n",
    "                return [float(tok) for tok in line.split()]\n",
    "        return []\n",
    "    \n",
    "    def load_power_txt(self, txt_path: str):\n",
    "        \"\"\"Read power file and return 1-D numpy array of power values\"\"\"\n",
    "        vals = []\n",
    "        with open(txt_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            # find first numeric row like: \"1\\t0.00000\"\n",
    "            in_numeric = False\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                if not in_numeric and re.match(r'^\\d+\\s+', line):\n",
    "                    in_numeric = True\n",
    "                if in_numeric and re.match(r'^\\d+\\s+', line):\n",
    "                    parts = re.split(r'\\s+', line)\n",
    "                    if len(parts) >= 2:\n",
    "                        try:\n",
    "                            vals.append(float(parts[1]))  # second column = power\n",
    "                        except ValueError:\n",
    "                            pass\n",
    "        if not vals:\n",
    "            raise ValueError(f\"No numeric power values in {txt_path}\")\n",
    "        return np.asarray(vals, dtype=float)\n",
    "   \n",
    "    def load_multi_column_file (self, filename):\n",
    "        #Load multicolumn metric file like powerAll and COMVelo2 and also single ones\n",
    "        path = os.path.join(self.folder_path, filename)\n",
    "        \n",
    "        if not os.path.exists(path):\n",
    "            print(f\"{filename} not found in {self.folder_path}\")\n",
    "            return None, None, None\n",
    "        \n",
    "        try:\n",
    "            data = []\n",
    "            max_len = 0\n",
    "            with open(path, 'r') as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if not line:\n",
    "                        continue\n",
    "                    parts = re.split(r'\\s+', line)\n",
    "                    try:\n",
    "                        row = [float(x) for x in parts]\n",
    "                        data.append(row)\n",
    "                        if len(row) > max_len:\n",
    "                                max_len = len(row)\n",
    "                    except ValueError:\n",
    "                        continue  # skip non-numeric lines\n",
    "\n",
    "            # Pad rows to same length with np.nan\n",
    "            for i in range(len(data)):\n",
    "                if len(data[i]) < max_len:\n",
    "                    data[i] += [np.nan] * (max_len - len(data[i]))\n",
    "\n",
    "            return np.array(data, dtype=float)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def generate_power_curves_from_powerMAG(self):\n",
    "        \"\"\" Generate individual powerCurve_pitchX.txt files from powerMAG.txt for each pitch. Handles inconsistent row lengths safely.\"\"\"\n",
    "        mag_path = os.path.join(self.folder_path, \"powerMAG.txt\")\n",
    "        if not os.path.exists(mag_path):\n",
    "            print(f\"powerMAG.txt not found in {self.folder_path}\")\n",
    "            return []\n",
    "\n",
    "        try:\n",
    "            numeric_lines = []\n",
    "            max_cols = 0\n",
    "\n",
    "            # Read numeric rows and track max column count\n",
    "            with open(mag_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if not line or re.match(r\"[A-Za-z]\", line):\n",
    "                        continue\n",
    "                    parts = re.split(r\"\\s+\", line)\n",
    "                    try:\n",
    "                        row = [float(x) for x in parts]\n",
    "                        numeric_lines.append(row)\n",
    "                        if len(row) > max_cols:\n",
    "                            max_cols = len(row)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "\n",
    "            # Pad rows to same length\n",
    "            for i in range(len(numeric_lines)):\n",
    "                if len(numeric_lines[i]) < max_cols:\n",
    "                    numeric_lines[i] += [np.nan] * (max_cols - len(numeric_lines[i]))\n",
    "\n",
    "            data = np.array(numeric_lines)\n",
    "\n",
    "            if data.ndim < 2 or data.shape[1] < 2:\n",
    "                print(\"powerMAG.txt does not contain multiple pitch columns.\")\n",
    "                return []\n",
    "\n",
    "            num_pitches = data.shape[1] - 1  # first column = item/time\n",
    "            print(f\"Detected {num_pitches} pitches in powerMAG.txt\")\n",
    "\n",
    "            curve_paths = []\n",
    "\n",
    "            for pitch_idx in range(num_pitches):\n",
    "                power_values = data[:, pitch_idx + 1]  # skip first column\n",
    "                curve_path = os.path.join(self.folder_path, f\"powerCurve_pitch{pitch_idx + 1}.txt\")\n",
    "                with open(curve_path, \"w\") as out:\n",
    "                    for i, val in enumerate(power_values, start=1):\n",
    "                        if np.isnan(val):\n",
    "                            continue\n",
    "                        out.write(f\"{i}\\t{val:.6f}\\n\")\n",
    "                curve_paths.append(curve_path)\n",
    "                print(f\"Created {os.path.basename(curve_path)}\")\n",
    "\n",
    "            return curve_paths\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating power curves: {e}\")\n",
    "            return []\n",
    "\n",
    "    \n",
    "    def analyze_power_curve(self, power, fs_hz: float = 1000.0):\n",
    "        \"\"\"Base metrics for power curve analysis\"\"\"\n",
    "        p = np.asarray(power, dtype=float)\n",
    "        n = p.size\n",
    "        t = np.arange(n) / fs_hz\n",
    "        \n",
    "        # Find peak power and time to peak\n",
    "        pk_idx = int(np.nanargmax(p))\n",
    "        peak_power = float(p[pk_idx])\n",
    "        time_to_peak = float(t[pk_idx])\n",
    "        \n",
    "        # Calculate area under curve (AUC)\n",
    "        auc = float(np.trapz(p, t))\n",
    "        \n",
    "        return {\n",
    "            \"peak_power\": peak_power,\n",
    "            \"time_to_peak\": time_to_peak,\n",
    "            \"auc\": auc\n",
    "        }\n",
    "\n",
    "    def compute_metrics_per_axis(self, data):\n",
    "        \"\"\"Compute metrics (peak, time_to_peak, auc) for each axis of a pitch\"\"\"\n",
    "        data = np.asarray(data)\n",
    "        metrics = {}\n",
    "    \n",
    "        if data.ndim == 1:\n",
    "            # single-column\n",
    "            metrics['X'] = {\n",
    "                'peak': np.max(data),\n",
    "                'time_to_peak': np.argmax(data)/1000,\n",
    "                'auc': np.trapz(data)\n",
    "            }\n",
    "        else:\n",
    "            # multi-column\n",
    "            for i, axis in enumerate(['X','Y','Z']):\n",
    "                col = data[:,i]\n",
    "                metrics[axis] = {\n",
    "                    'peak': np.max(col),\n",
    "                    'time_to_peak': np.argmax(col)/1000,\n",
    "                    'auc': np.trapz(col)\n",
    "                }\n",
    "        return metrics\n",
    "\n",
    "    \n",
    "    def process_power_files(self):\n",
    "        \"\"\"Process all power files and calculate metrics\"\"\"\n",
    "        power_files = {\n",
    "            \"pelvis\": \"pelvisPower.txt\",\n",
    "            \"shoulder\": \"shoulderPower.txt\", \n",
    "            \"elbow\": \"elbowPower.txt\",\n",
    "            \"fs1\": \"FS1.txt\"\n",
    "        }\n",
    "        \n",
    "        power_metrics = {}\n",
    "        \n",
    "        for file_type, filename in power_files.items():\n",
    "            file_path = os.path.join(self.folder_path, filename)\n",
    "            \n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"{filename} not found in {self.folder_path}\")\n",
    "                power_metrics[file_type] = {\n",
    "                    \"peak_power\": None,\n",
    "                    \"time_to_peak\": None,\n",
    "                    \"auc\": None\n",
    "                }\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                power_data = self.load_power_txt(file_path)\n",
    "                metrics = self.analyze_power_curve(power_data)\n",
    "                power_metrics[file_type] = metrics\n",
    "                print(f\"Processed {filename}: Peak Power = {metrics['peak_power']:.2f}W\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "                power_metrics[file_type] = {\n",
    "                    \"peak_power\": None,\n",
    "                    \"time_to_peak\": None,\n",
    "                    \"auc\": None\n",
    "                }\n",
    "        \n",
    "        return power_metrics\n",
    "    \n",
    "    def insert_power_data(self, pitch_id, power_exports_data, power_metrics):\n",
    "        \"\"\"Insert one row of pitch data into the database\"\"\"\n",
    "        cols = [\n",
    "            \"pitch_id\", \n",
    "            \"PowerALL_X\", \"PowerALL_Y\", \"PowerALL_Z\",\n",
    "            \"Center_of_Mass_Vel2_X\", \"Center_of_Mass_Vel2_Y\", \"Center_of_Mass_Vel2_Z\",\n",
    "            \"PowerMAG\", \"Foot_Contact\", \"Release\", \"Release100ms\",\n",
    "            \"pelvis_peak_power\", \"pelvis_time_to_peak\", \"pelvis_auc\",\n",
    "            \"shoulder_peak_power\", \"shoulder_time_to_peak\", \"shoulder_auc\",\n",
    "            \"elbow_peak_power\", \"elbow_time_to_peak\", \"elbow_auc\",\n",
    "            \"power_curve_peak_power\", \"power_curve_time_to_peak\", \"power_curve_auc\",\n",
    "            \"fs1_peak_power\", \"fs1_time_to_peak\", \"fs1_auc\"\n",
    "        ]\n",
    "    \n",
    "        vals = [\n",
    "            pitch_id, \n",
    "            power_exports_data.get(\"PowerALL_X\"),\n",
    "            power_exports_data.get(\"PowerALL_Y\"),\n",
    "            power_exports_data.get(\"PowerALL_Z\"),\n",
    "            power_exports_data.get(\"COMVelo2_X\"),\n",
    "            power_exports_data.get(\"COMVelo2_Y\"),\n",
    "            power_exports_data.get(\"COMVelo2_Z\"),\n",
    "            power_exports_data.get(\"PowerMAG\"),\n",
    "            power_exports_data.get(\"footContact\"),\n",
    "            power_exports_data.get(\"release\"),\n",
    "            power_exports_data.get(\"releaseAfter\"),\n",
    "            power_metrics[\"pelvis\"][\"peak_power\"],\n",
    "            power_metrics[\"pelvis\"][\"time_to_peak\"],\n",
    "            power_metrics[\"pelvis\"][\"auc\"],\n",
    "            power_metrics[\"shoulder\"][\"peak_power\"],\n",
    "            power_metrics[\"shoulder\"][\"time_to_peak\"],\n",
    "            power_metrics[\"shoulder\"][\"auc\"],\n",
    "            power_metrics[\"elbow\"][\"peak_power\"],\n",
    "            power_metrics[\"elbow\"][\"time_to_peak\"],\n",
    "            power_metrics[\"elbow\"][\"auc\"],\n",
    "            power_metrics[\"power_curve\"][\"peak_power\"],\n",
    "            power_metrics[\"power_curve\"][\"time_to_peak\"],\n",
    "            power_metrics[\"power_curve\"][\"auc\"],\n",
    "            power_metrics[\"fs1\"][\"peak_power\"],\n",
    "            power_metrics[\"fs1\"][\"time_to_peak\"],\n",
    "            power_metrics[\"fs1\"][\"auc\"]\n",
    "        ]\n",
    "    \n",
    "        placeholders = \",\".join([\"?\"] * len(vals))\n",
    "        self.cursor.execute(f\"INSERT INTO Power_Analysis ({','.join(cols)}) VALUES ({placeholders})\", vals)\n",
    "        self.conn.commit()\n",
    "\n",
    "    def run_analysis(self):\n",
    "        \"\"\"Run full power analysis for all pitches in the folder\"\"\"\n",
    "        print(\"Starting Power Analysis...\")\n",
    "\n",
    "        # select folder\n",
    "        if not self.select_folder():\n",
    "            return False\n",
    "\n",
    "        # connect to existing database\n",
    "        self.connect_to_existing_db()\n",
    "\n",
    "        # 3️⃣ Parse XML for demographics and measurement info\n",
    "        xml_file_path = ''\n",
    "        for root_dir, _, files in os.walk(self.folder_path):\n",
    "            for file in files:\n",
    "                if file.lower() == 'session.xml':\n",
    "                    xml_file_path = os.path.join(root_dir, file)\n",
    "                    break\n",
    "            if xml_file_path:\n",
    "                break\n",
    "        if not xml_file_path:\n",
    "            print(\"No session.xml found in folder.\")\n",
    "            return False\n",
    "\n",
    "        tree = ET.parse(xml_file_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        def find_text(element, tag):\n",
    "            found = element.find(tag)\n",
    "            return found.text if found is not None else None\n",
    "\n",
    "        # Subject info\n",
    "        subject_fields = root.find(\"Fields\")\n",
    "        if subject_fields is None:\n",
    "            print(\"No Subject Fields in XML\")\n",
    "            return False\n",
    "\n",
    "        subject_info = {\n",
    "            \"name\": find_text(subject_fields, \"Name\"),\n",
    "            \"dob\": (find_text(subject_fields, \"Date_of_Birth\") or find_text(subject_fields, \"Date_of_birth\") or find_text(subject_fields,\"date_of_birth\")),\n",
    "            \"height\": find_text(subject_fields, \"Height\"),\n",
    "            \"weight\": find_text(subject_fields, \"Weight\"),\n",
    "            \"creation_date\": find_text(subject_fields, \"Creation_date\")\n",
    "        }\n",
    "\n",
    "        # --- Normalize / clean subject info before inserting\n",
    "        subject_info[\"name\"] = subject_info[\"name\"].strip() if subject_info[\"name\"] else None\n",
    "        subject_info[\"dob\"] = subject_info[\"dob\"].strip() if subject_info[\"dob\"] else None\n",
    "        subject_info[\"height\"] = float(subject_info[\"height\"]) if subject_info[\"height\"] else None\n",
    "        subject_info[\"weight\"] = float(subject_info[\"weight\"]) if subject_info[\"weight\"] else None\n",
    "        subject_info[\"creation_date\"] = subject_info[\"creation_date\"].strip() if subject_info[\"creation_date\"] else None\n",
    "\n",
    "        # Measurement info (used Fastball RH measurements)\n",
    "        measurement_info = []\n",
    "        for measurement in root.findall(\".//Measurement[@Type='Fastball RH']\"):\n",
    "            fields = measurement.find(\"Fields\")\n",
    "            if fields is None:\n",
    "                continue\n",
    "            used = find_text(fields, \"Used\")\n",
    "            if used and used.lower() == 'true':\n",
    "                filename = measurement.get(\"Filename\")\n",
    "                comments = find_text(fields, \"Comments\") or ''\n",
    "                m_creation_date = find_text(fields, \"Creation_date\") or subject_info[\"creation_date\"]\n",
    "                if filename:\n",
    "                    measurement_info.append((filename, comments, m_creation_date))\n",
    "\n",
    "        if not measurement_info:\n",
    "            print(\"No Fastball measurements found. Exiting.\")\n",
    "            return False\n",
    "        \n",
    "        # load all multi-column files\n",
    "        powerAll_data = self.load_multi_column_file(\"powerAll.txt\")\n",
    "        COMVelo2_data = self.load_multi_column_file(\"COMVelo2.txt\")\n",
    "        powerMAG_data = self.load_multi_column_file(\"powerMAG.txt\")\n",
    "        footContact_data = self.load_multi_column_file(\"footContact.txt\")\n",
    "        release_data = self.load_multi_column_file(\"release.txt\")\n",
    "        releaseAfter_data = self.load_multi_column_file(\"releaseAfter.txt\")\n",
    "\n",
    "        if powerAll_data is None:\n",
    "            print(\"Failed to load required files\")\n",
    "            return False\n",
    "\n",
    "        \n",
    "        # determine number of pitches (3 columns per pitch + 1 item column)\n",
    "        num_columns = len(powerAll_data[0])\n",
    "        num_pitches = (num_columns - 1) // 3\n",
    "        print(f\"Detected {num_pitches} pitches in powerAll.txt\")\n",
    "\n",
    "        #generate power curves and compute metrics\n",
    "        curve_paths = self.generate_power_curves_from_powerMAG()\n",
    "        \n",
    "        # process joint power files (pelvis, shoulder, elbow, fs1, etc.)\n",
    "        power_metrics = self.process_power_files()\n",
    "\n",
    "        # Compute metrics for each curve\n",
    "        power_metrics[\"power_curve\"] = {}\n",
    "        if curve_paths:\n",
    "            # For simplicity, take the first one (or you can average them)\n",
    "            first_curve_vals = self.load_power_txt(curve_paths[0])\n",
    "            power_metrics[\"power_curve\"] = self.analyze_power_curve(first_curve_vals)\n",
    "        else:\n",
    "            power_metrics[\"power_curve\"] = {\"peak_power\": None, \"time_to_peak\": None, \"auc\": None}\n",
    "\n",
    "\n",
    "\n",
    "        # loop over each pitch\n",
    "        # loop over each measurement (filename)\n",
    "        for meas in measurement_info:\n",
    "            filename, comments, m_creation_date = meas\n",
    "            pitch_id = self.extract_pitch_id(filename) or 0  # fallback to 0 if not found\n",
    "\n",
    "            # Loop over each row/sample\n",
    "            for row_idx, row in enumerate(powerAll_data):\n",
    "                # PowerALL values for this pitch\n",
    "                col_start = (pitch_id - 1) * 3 + 1\n",
    "                col_end = col_start + 3\n",
    "                if len(row) < col_end:\n",
    "                    continue\n",
    "                power_vals = row[col_start:col_end]\n",
    "\n",
    "                # COMVelo2\n",
    "                if COMVelo2_data is not None and row_idx < len(COMVelo2_data):\n",
    "                    com_row = COMVelo2_data[row_idx]\n",
    "                    if len(com_row) >= col_end:\n",
    "                        com_vals = com_row[col_start:col_end]\n",
    "                    else:\n",
    "                        com_vals = [None, None, None]\n",
    "                else:\n",
    "                    com_vals = [None, None, None]\n",
    "\n",
    "                # PowerMAG\n",
    "                if powerMAG_data is not None and row_idx < len(powerMAG_data):\n",
    "                    pm_row = powerMAG_data[row_idx]\n",
    "                    powerMAG_val = pm_row[pitch_id] if len(pm_row) > pitch_id else None\n",
    "                else:\n",
    "                    powerMAG_val = None\n",
    "\n",
    "                # Foot contact / release\n",
    "                # Foot contact / release values\n",
    "                if footContact_data is not None and row_idx < len(footContact_data):\n",
    "                    fc_row = footContact_data[row_idx]\n",
    "                    foot_contact = fc_row[pitch_id] if len(fc_row) > pitch_id else None\n",
    "                else:\n",
    "                    foot_contact = None\n",
    "\n",
    "                if release_data is not None and row_idx < len(release_data):\n",
    "                    r_row = release_data[row_idx]\n",
    "                    release = r_row[pitch_id] if len(r_row) > pitch_id else None\n",
    "                else:\n",
    "                    release = None\n",
    "\n",
    "                if releaseAfter_data is not None and row_idx < len(releaseAfter_data):\n",
    "                    ra_row = releaseAfter_data[row_idx]\n",
    "                    release100ms = ra_row[pitch_id] if len(ra_row) > pitch_id else None\n",
    "                else:\n",
    "                    release100ms = None\n",
    "\n",
    "                vals = (\n",
    "                    pitch_id,\n",
    "                    subject_info[\"name\"],\n",
    "                    subject_info[\"dob\"],\n",
    "                    subject_info[\"height\"],\n",
    "                    subject_info[\"weight\"],\n",
    "                    filename,\n",
    "                    comments,\n",
    "                    m_creation_date,\n",
    "                    power_vals[0] if len(power_vals) > 0 else None,\n",
    "                    power_vals[1] if len(power_vals) > 1 else None,\n",
    "                    power_vals[2] if len(power_vals) > 2 else None,\n",
    "                    powerMAG_val,\n",
    "                    com_vals[0],\n",
    "                    com_vals[1],\n",
    "                    com_vals[2],\n",
    "                    foot_contact,\n",
    "                    release,\n",
    "                    release100ms,\n",
    "                    power_metrics[\"pelvis\"][\"peak_power\"],\n",
    "                    power_metrics[\"pelvis\"][\"time_to_peak\"],\n",
    "                    power_metrics[\"pelvis\"][\"auc\"],\n",
    "                    power_metrics[\"shoulder\"][\"peak_power\"],\n",
    "                    power_metrics[\"shoulder\"][\"time_to_peak\"],\n",
    "                    power_metrics[\"shoulder\"][\"auc\"],\n",
    "                    power_metrics[\"elbow\"][\"peak_power\"],\n",
    "                    power_metrics[\"elbow\"][\"time_to_peak\"],\n",
    "                    power_metrics[\"elbow\"][\"auc\"],\n",
    "                    power_metrics[\"power_curve\"][\"peak_power\"],\n",
    "                    power_metrics[\"power_curve\"][\"time_to_peak\"],\n",
    "                    power_metrics[\"power_curve\"][\"auc\"],\n",
    "                    power_metrics[\"fs1\"][\"peak_power\"],\n",
    "                    power_metrics[\"fs1\"][\"time_to_peak\"],\n",
    "                    power_metrics[\"fs1\"][\"auc\"]\n",
    "                )\n",
    "\n",
    "                self.cursor.execute(\"\"\"\n",
    "                    INSERT INTO Power_Analysis (\n",
    "                        pitch_id, Name, Date_of_Birth, Height, Weight,\n",
    "                        Filename, Comments, Creation_Date,\n",
    "                        PowerALL_X, PowerALL_Y, PowerALL_Z,\n",
    "                        PowerMAG, Center_of_Mass_Vel2_X, Center_of_Mass_Vel2_Y, Center_of_Mass_Vel2_Z,\n",
    "                        Foot_Contact, Release, Release100ms,\n",
    "                        pelvis_peak_power, pelvis_time_to_peak, pelvis_auc,\n",
    "                        shoulder_peak_power, shoulder_time_to_peak, shoulder_auc,\n",
    "                        elbow_peak_power, elbow_time_to_peak, elbow_auc,\n",
    "                        power_curve_peak_power, power_curve_time_to_peak, power_curve_auc,\n",
    "                        fs1_peak_power, fs1_time_to_peak, fs1_auc\n",
    "                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "                \"\"\", vals)\n",
    "\n",
    "            self.conn.commit()\n",
    "            print(f\"Inserted pitch {pitch_id} data ({len(powerAll_data)} samples).\")\n",
    "\n",
    "        self.conn.close()\n",
    "        print(\"Power analysis completed\")\n",
    "        print(f\"Database saved at: {self.db_path}\")\n",
    "        return True\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main entry point\"\"\"\n",
    "    analyzer = PowerAnalyzer()\n",
    "    success = analyzer.run_analysis()\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\nAnalysis completed\")\n",
    "    else:\n",
    "        print(\"\\nAnalysis failed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "      main()\n"
   ],
   "id": "56b42cdb959c8d6c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
