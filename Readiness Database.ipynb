{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-19T17:28:55.690773Z",
     "start_time": "2024-12-19T17:28:46.952451Z"
    }
   },
   "source": [
    "# This is my main readiness code. Runs everything\n",
    "\n",
    "import os\n",
    "import sqlite3\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "# Database file path\n",
    "db_path = 'D:/Readiness Screen 3/Readiness_Screen_Data.db'\n",
    "\n",
    "# Establish connection and create tables\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create tables\n",
    "cursor.executescript(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Participant (\n",
    "    Participant_ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Name TEXT,\n",
    "    Height REAL,\n",
    "    Weight REAL,\n",
    "    Plyo_Day TEXT,\n",
    "    Creation_Date TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS I (\n",
    "    Trial_ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Name TEXT,\n",
    "    Participant_ID INTEGER,\n",
    "    Avg_Force REAL,\n",
    "    Avg_Force_Norm REAL,\n",
    "    Max_Force REAL,\n",
    "    Max_Force_Norm REAL,\n",
    "    Time_to_Max REAL,\n",
    "    FOREIGN KEY (Participant_ID) REFERENCES Participant(Participant_ID)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS Y (\n",
    "    Trial_ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Name TEXT,\n",
    "    Participant_ID INTEGER,\n",
    "    Avg_Force REAL,\n",
    "    Avg_Force_Norm REAL,\n",
    "    Max_Force REAL,\n",
    "    Max_Force_Norm REAL,\n",
    "    Time_to_Max REAL,\n",
    "    FOREIGN KEY (Participant_ID) REFERENCES Participant(Participant_ID)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS T (\n",
    "    Trial_ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Name TEXT,\n",
    "    Participant_ID INTEGER,\n",
    "    Avg_Force REAL,\n",
    "    Avg_Force_Norm REAL,\n",
    "    Max_Force REAL,\n",
    "    Max_Force_Norm REAL,\n",
    "    Time_to_Max REAL,\n",
    "    FOREIGN KEY (Participant_ID) REFERENCES Participant(Participant_ID)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS IR90 (\n",
    "    Trial_ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Name TEXT,\n",
    "    Participant_ID INTEGER,\n",
    "    Avg_Force REAL,\n",
    "    Avg_Force_Norm REAL,\n",
    "    Max_Force REAL,\n",
    "    Max_Force_Norm REAL,\n",
    "    Time_to_Max REAL,\n",
    "    FOREIGN KEY (Participant_ID) REFERENCES Participant(Participant_ID)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS CMJ (\n",
    "    Trial_ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Name TEXT,\n",
    "    Participant_ID INTEGER,\n",
    "    Jump_Height REAL,\n",
    "    Peak_Power REAL,\n",
    "    Peak_Force REAL,\n",
    "    FOREIGN KEY (Participant_ID) REFERENCES Participant(Participant_ID)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS PPU (\n",
    "    Trial_ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Name TEXT,\n",
    "    Participant_ID INTEGER,\n",
    "    Jump_Height REAL,\n",
    "    Peak_Power REAL,\n",
    "    Peak_Force REAL,\n",
    "    FOREIGN KEY (Participant_ID) REFERENCES Participant(Participant_ID)\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Prompt user to select a folder\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "selected_folder = filedialog.askdirectory(initialdir='D:/Readiness Screen 3/Data/')\n",
    "\n",
    "if not selected_folder:\n",
    "    print(\"No folder selected. Exiting...\")\n",
    "    exit()\n",
    "\n",
    "# Locate the XML file\n",
    "xml_file_path = ''\n",
    "for root_dir, _, files in os.walk(selected_folder):\n",
    "    for file in files:\n",
    "        if file.lower().startswith('session') and file.lower().endswith('.xml'):\n",
    "            xml_file_path = os.path.join(root_dir, file)\n",
    "            break\n",
    "    if xml_file_path:\n",
    "        break\n",
    "\n",
    "if not xml_file_path:\n",
    "    print(\"No XML file found. Exiting...\")\n",
    "    exit()\n",
    "\n",
    "# Parse the XML file\n",
    "tree = ET.parse(xml_file_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "def find_text(element, tag):\n",
    "    found = element.find(tag)\n",
    "    return found.text if found is not None else None\n",
    "\n",
    "session_fields = root.find(\".//Session/Fields\")\n",
    "name = find_text(session_fields, \"Name\")\n",
    "height = find_text(session_fields, \"Height\")\n",
    "weight = find_text(session_fields, \"Weight\")\n",
    "plyo_day = find_text(session_fields, \"Plyo_Day\")\n",
    "creation_date = find_text(session_fields, \"Creation_date\")\n",
    "\n",
    "if None in [name, height, weight, plyo_day, creation_date]:\n",
    "    print(\"Missing data in XML file. Exiting...\")\n",
    "    exit()\n",
    "\n",
    "# Insert participant data\n",
    "cursor.execute(\"\"\"\n",
    "INSERT INTO Participant (Name, Height, Weight, Plyo_Day, Creation_Date)\n",
    "VALUES (?, ?, ?, ?, ?)\n",
    "\"\"\", (name, height, weight, plyo_day, creation_date))\n",
    "participant_id = cursor.lastrowid\n",
    "conn.commit()\n",
    "\n",
    "# Define ASCII file mapping and output path\n",
    "ascii_files = {\n",
    "    \"I\": \"i_data.txt\",\n",
    "    \"Y\": \"y_data.txt\",\n",
    "    \"T\": \"t_data.txt\",\n",
    "    \"IR90\": \"ir90_data.txt\",\n",
    "    \"CMJ\": \"cmj_data.txt\",\n",
    "    \"PPU\": \"ppu_data.txt\"\n",
    "}\n",
    "output_path = 'D:/Readiness Screen 3/Output Files/'\n",
    "\n",
    "# Process files in the ASCII file dictionary\n",
    "for file_key, file_name in ascii_files.items():\n",
    "    file_path = os.path.join(output_path, file_name)\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        try:\n",
    "            # Skip rows and explicitly set headers\n",
    "            if file_key in [\"I\", \"Y\", \"T\", \"IR90\"]:\n",
    "                headers = [\"Max_Force\", \"Max_Force_Norm\", \"Avg_Force\", \"Avg_Force_Norm\", \"Time_to_Max\"]\n",
    "                df = pd.read_csv(file_path, sep='\\s+', skiprows=5, names=headers)\n",
    "            elif file_key in [\"CMJ\", \"PPU\"]:\n",
    "                headers = [\"JH_IN\", \"LEWIS_PEAK_POWER\", \"Max_Force\"]\n",
    "                df = pd.read_csv(file_path, sep='\\s+', skiprows=5, names=headers)\n",
    "            \n",
    "            # Print a preview for debugging\n",
    "            print(f\"Data from {file_name}:\")\n",
    "            print(df.head())\n",
    "            \n",
    "            # Insert data into the database\n",
    "            table_name = file_key.upper()  # Use the file key as the table name\n",
    "            # Insert data into the database\n",
    "            for _, row in df.iterrows():\n",
    "                if file_key in [\"I\", \"Y\", \"T\", \"IR90\"]:\n",
    "                    cursor.execute(f\"\"\"\n",
    "                    INSERT INTO {table_name} \n",
    "                    (Name, Participant_ID, Avg_Force, Avg_Force_Norm, Max_Force, Max_Force_Norm, Time_to_Max)\n",
    "                    VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "                    \"\"\", (name, participant_id, row['Avg_Force'], row['Avg_Force_Norm'], row['Max_Force'], row['Max_Force_Norm'], row['Time_to_Max']))\n",
    "                elif file_key in [\"CMJ\", \"PPU\"]:\n",
    "                    cursor.execute(f\"\"\"\n",
    "                    INSERT INTO {table_name} \n",
    "                    (Name, Participant_ID, Jump_Height, Peak_Power, Peak_Force)\n",
    "                    VALUES (?, ?, ?, ?, ?)\n",
    "                    \"\"\", (name, participant_id, row['JH_IN'], row['LEWIS_PEAK_POWER'], row['Max_Force']))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {e}\")\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "\n",
    "# Commit changes and close the database connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Data successfully added to the database.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: D:/Readiness Screen 3/Output Files/i_data.txt\n",
      "Data from i_data.txt:\n",
      "   Max_Force  Max_Force_Norm  Avg_Force  Avg_Force_Norm  Time_to_Max\n",
      "1      148.3             1.7      128.4            1.47         3.13\n",
      "Processing file: D:/Readiness Screen 3/Output Files/y_data.txt\n",
      "Data from y_data.txt:\n",
      "   Max_Force  Max_Force_Norm  Avg_Force  Avg_Force_Norm  Time_to_Max\n",
      "1      114.0             1.3       97.7            1.12         3.22\n",
      "Processing file: D:/Readiness Screen 3/Output Files/t_data.txt\n",
      "Data from t_data.txt:\n",
      "   Max_Force  Max_Force_Norm  Avg_Force  Avg_Force_Norm  Time_to_Max\n",
      "1      105.3             1.2       90.6            1.04         1.93\n",
      "Processing file: D:/Readiness Screen 3/Output Files/ir90_data.txt\n",
      "Data from ir90_data.txt:\n",
      "   Max_Force  Max_Force_Norm  Avg_Force  Avg_Force_Norm  Time_to_Max\n",
      "1      122.9             1.4      109.8            1.26         0.36\n",
      "Processing file: D:/Readiness Screen 3/Output Files/cmj_data.txt\n",
      "Data from cmj_data.txt:\n",
      "   JH_IN  LEWIS_PEAK_POWER  Max_Force\n",
      "1  19.77           8066.29    5159.41\n",
      "Processing file: D:/Readiness Screen 3/Output Files/ppu_data.txt\n",
      "Data from ppu_data.txt:\n",
      "   JH_IN  LEWIS_PEAK_POWER  Max_Force\n",
      "1   0.02           4960.27    3261.87\n",
      "Data successfully added to the database.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T17:28:56.082668Z",
     "start_time": "2024-12-19T17:28:55.691782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sqlite3\n",
    "\n",
    "\n",
    "db_path = \"D:/Readiness Screen 3/Readiness_Screen_Data.db\" \n",
    "sort_column = \"Name\"     \n",
    "\n",
    "def reorder_all_tables(db_path, sort_column):\n",
    "    try:\n",
    "        # Connect to the database\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Fetch all table names in the database\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        tables = cursor.fetchall()\n",
    "\n",
    "        for table in tables:\n",
    "            table_name = table[0]\n",
    "\n",
    "            # Skip system tables like sqlite_sequence\n",
    "            if table_name.startswith(\"sqlite_\"):\n",
    "                continue\n",
    "\n",
    "            print(f\"Processing table: {table_name}\")\n",
    "\n",
    "            # Check if the column exists in the current table\n",
    "            cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "            columns = [info[1] for info in cursor.fetchall()]\n",
    "            if sort_column not in columns:\n",
    "                print(f\"Skipping table '{table_name}' - Column '{sort_column}' not found.\")\n",
    "                continue\n",
    "\n",
    "            # Create a new sorted table\n",
    "            temp_table = f\"{table_name}_sorted\"\n",
    "            cursor.execute(f\"CREATE TABLE {temp_table} AS SELECT * FROM {table_name} ORDER BY {sort_column} ASC;\")\n",
    "            \n",
    "            # Drop the old table\n",
    "            cursor.execute(f\"DROP TABLE {table_name};\")\n",
    "            \n",
    "            # Rename the new table to the original name\n",
    "            cursor.execute(f\"ALTER TABLE {temp_table} RENAME TO {table_name};\")\n",
    "            print(f\"Table '{table_name}' reordered successfully.\")\n",
    "\n",
    "        # Commit changes\n",
    "        conn.commit()\n",
    "        print(\"All tables processed.\")\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "reorder_all_tables(db_path, sort_column)\n"
   ],
   "id": "b88ed19b32a83688",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table: Participant\n",
      "Table 'Participant' reordered successfully.\n",
      "Processing table: I\n",
      "Table 'I' reordered successfully.\n",
      "Processing table: Y\n",
      "Table 'Y' reordered successfully.\n",
      "Processing table: T\n",
      "Table 'T' reordered successfully.\n",
      "Processing table: IR90\n",
      "Table 'IR90' reordered successfully.\n",
      "Processing table: CMJ\n",
      "Table 'CMJ' reordered successfully.\n",
      "Processing table: PPU\n",
      "Table 'PPU' reordered successfully.\n",
      "All tables processed.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T22:12:37.771741Z",
     "start_time": "2024-12-20T22:12:37.461845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ---------------------------\n",
    "# Step 1: Data Loading\n",
    "# ---------------------------\n",
    "\n",
    "conn = sqlite3.connect('D:/Readiness Screen 3/Readiness_Screen_Data.db')\n",
    "\n",
    "df_cmj = pd.read_sql_query(\"SELECT Name, Creation_Date, Jump_Height AS Jump_Height_CMJ FROM CMJ;\", conn)\n",
    "df_ppu = pd.read_sql_query(\"SELECT Name, Creation_Date, Jump_Height AS Jump_Height_PPU FROM PPU;\", conn)\n",
    "df_i = pd.read_sql_query(\"SELECT Name, Creation_Date, Avg_Force AS Avg_Force_I FROM I;\", conn)\n",
    "df_y = pd.read_sql_query(\"SELECT Name, Creation_Date, Avg_Force AS Avg_Force_Y FROM Y;\", conn)\n",
    "df_t = pd.read_sql_query(\"SELECT Name, Creation_Date, Avg_Force AS Avg_Force_T FROM T;\", conn)\n",
    "df_ir90 = pd.read_sql_query(\"SELECT Name, Creation_Date, Avg_Force AS Avg_Force_IR90 FROM IR90;\", conn)\n",
    "conn.close()\n",
    "\n",
    "df_merged = df_cmj.merge(df_ppu, on=[\"Name\", \"Creation_Date\"], how=\"outer\")\n",
    "df_merged = df_merged.merge(df_i, on=[\"Name\", \"Creation_Date\"], how=\"outer\")\n",
    "df_merged = df_merged.merge(df_y, on=[\"Name\", \"Creation_Date\"], how=\"outer\")\n",
    "df_merged = df_merged.merge(df_t, on=[\"Name\", \"Creation_Date\"], how=\"outer\")\n",
    "df_merged = df_merged.merge(df_ir90, on=[\"Name\", \"Creation_Date\"], how=\"outer\")\n",
    "\n",
    "df_merged['Creation_Date'] = pd.to_datetime(df_merged['Creation_Date'])\n",
    "\n",
    "df_merged = df_merged.sort_values(by=\"Creation_Date\")\n",
    "\n",
    "participants = df_merged['Name'].dropna().unique()\n",
    "\n",
    "# ---------------------------\n",
    "# Step 2: Initialize the Dash App\n",
    "# ---------------------------\n",
    "\n",
    "app = Dash(__name__)\n",
    "\n",
    "# ---------------------------\n",
    "# Step 3: Dash Layout\n",
    "# ---------------------------\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Participant Measurements Over Time\"),\n",
    "\n",
    "    html.Div([\n",
    "        html.Label(\"Select a Participant:\"),\n",
    "        dcc.Dropdown(\n",
    "            id='participant-dropdown',\n",
    "            options=[{'label': p, 'value': p} for p in participants],\n",
    "            value=participants[0] if len(participants) > 0 else None,\n",
    "            clearable=False\n",
    "        )\n",
    "    ], style={'width': '30%', 'display': 'inline-block'}),\n",
    "\n",
    "    dcc.Graph(id='measurements-graph')\n",
    "])\n",
    "\n",
    "# ---------------------------\n",
    "# Step 4: Callbacks\n",
    "# ---------------------------\n",
    "\n",
    "@app.callback(\n",
    "    Output('measurements-graph', 'figure'),\n",
    "    [Input('participant-dropdown', 'value')]\n",
    ")\n",
    "def update_graph(selected_participant):\n",
    "    dff = df_merged[df_merged['Name'] == selected_participant]\n",
    "\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Use Creation_Date as your x-axis\n",
    "    if 'Jump_Height_CMJ' in dff.columns and dff['Jump_Height_CMJ'].notnull().any():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=dff['Creation_Date'], y=dff['Jump_Height_CMJ'], mode='lines+markers', name='Jump_Height_CMJ'\n",
    "        ))\n",
    "\n",
    "    if 'Jump_Height_PPU' in dff.columns and dff['Jump_Height_PPU'].notnull().any():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=dff['Creation_Date'], y=dff['Jump_Height_PPU'], mode='lines+markers', name='Jump_Height_PPU'\n",
    "        ))\n",
    "\n",
    "    if 'Avg_Force_I' in dff.columns and dff['Avg_Force_I'].notnull().any():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=dff['Creation_Date'], y=dff['Avg_Force_I'], mode='lines+markers', name='Avg_Force_I'\n",
    "        ))\n",
    "\n",
    "    if 'Avg_Force_Y' in dff.columns and dff['Avg_Force_Y'].notnull().any():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=dff['Creation_Date'], y=dff['Avg_Force_Y'], mode='lines+markers', name='Avg_Force_Y'\n",
    "        ))\n",
    "\n",
    "    if 'Avg_Force_T' in dff.columns and dff['Avg_Force_T'].notnull().any():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=dff['Creation_Date'], y=dff['Avg_Force_T'], mode='lines+markers', name='Avg_Force_T'\n",
    "        ))\n",
    "\n",
    "    if 'Avg_Force_IR90' in dff.columns and dff['Avg_Force_IR90'].notnull().any():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=dff['Creation_Date'], y=dff['Avg_Force_IR90'], mode='lines+markers', name='Avg_Force_IR90'\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Measurements Over Time for {selected_participant}\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Measurement Value\",\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "# ---------------------------\n",
    "# Step 5: Run the App\n",
    "# ---------------------------\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n",
    "    \n",
    "    Dash is running on http://127.0.0.1:8050/\n",
    "     * Serving Flask app \"__main__\" (lazy loading)\n",
    "     * Environment: production\n",
    "       ...\n",
    "     * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
    "\n"
   ],
   "id": "4a7e743df8763e29",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x25769a3c860>"
      ],
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T22:08:07.302825Z",
     "start_time": "2024-12-20T22:08:07.019644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Adds Creation_Date to all tables so that I can have UI for all tests\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect('D:/Readiness Screen 3/Readiness_Screen_Data.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# List of tables to update\n",
    "tables = [\"CMJ\", \"PPU\", \"I\", \"Y\", \"T\", \"IR90\"]\n",
    "\n",
    "# 1. Add Creation_Date column to each table if it doesn't exist yet\n",
    "for tbl in tables:\n",
    "    try:\n",
    "        cur.execute(f\"ALTER TABLE {tbl} ADD COLUMN Creation_Date TEXT;\")\n",
    "    except sqlite3.OperationalError:\n",
    "        # This typically happens if the column already exists. We can ignore or print a warning.\n",
    "        print(f\"Column Creation_Date already exists in {tbl} or another error occurred.\")\n",
    "\n",
    "# 2. Load participant data into a dictionary for quick lookups\n",
    "cur.execute(\"SELECT Name, Creation_Date FROM Participant;\")\n",
    "participants_data = dict(cur.fetchall())\n",
    "\n",
    "# 3. Update each measurement table\n",
    "for tbl in tables:\n",
    "    # Get all unique names from the current table\n",
    "    cur.execute(f\"SELECT DISTINCT Name FROM {tbl}\")\n",
    "    rows = cur.fetchall()\n",
    "    for (name,) in rows:\n",
    "        if name in participants_data:\n",
    "            creation_date = participants_data[name]\n",
    "            # Update all rows with this name in the table\n",
    "            cur.execute(f\"UPDATE {tbl} SET Creation_Date = ? WHERE Name = ?\", (creation_date, name))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Creation_Date columns added and populated successfully.\")\n"
   ],
   "id": "c5b14c0eb9f5ecc2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation_Date columns added and populated successfully.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7fd15a7a920fb781"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
