{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T15:32:36.815378Z",
     "start_time": "2025-06-10T15:32:21.364648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This is my main readiness code. \n",
    "# Prompts you to select folder and adds info into sqlite database at Readiness_Screen_Data.db\n",
    "\n",
    "import os\n",
    "import sqlite3\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "# Database file path\n",
    "db_path = 'D:/Readiness Screen 3/Readiness_Screen_Data.db'\n",
    "\n",
    "# Establish connection and create tables\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. Create/Update Tables with Correct Column Order\n",
    "# -------------------------------------------------\n",
    "cursor.executescript(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Participant (\n",
    "    Participant_ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Name TEXT,\n",
    "    Height REAL,\n",
    "    Weight REAL,\n",
    "    Plyo_Day TEXT,\n",
    "    Creation_Date TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS I (\n",
    "    Trial_ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Name TEXT,\n",
    "    Participant_ID INTEGER,\n",
    "    Avg_Force REAL,\n",
    "    Avg_Force_Norm REAL,\n",
    "    Max_Force REAL,\n",
    "    Max_Force_Norm REAL,\n",
    "    Time_to_Max REAL,\n",
    "    Creation_Date TEXT,\n",
    "    FOREIGN KEY (Participant_ID) REFERENCES Participant(Participant_ID)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS Y (\n",
    "    Trial_ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Name TEXT,\n",
    "    Participant_ID INTEGER,\n",
    "    Avg_Force REAL,\n",
    "    Avg_Force_Norm REAL,\n",
    "    Max_Force REAL,\n",
    "    Max_Force_Norm REAL,\n",
    "    Time_to_Max REAL,\n",
    "    Creation_Date TEXT,\n",
    "    FOREIGN KEY (Participant_ID) REFERENCES Participant(Participant_ID)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS T (\n",
    "    Trial_ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Name TEXT,\n",
    "    Participant_ID INTEGER,\n",
    "    Avg_Force REAL,\n",
    "    Avg_Force_Norm REAL,\n",
    "    Max_Force REAL,\n",
    "    Max_Force_Norm REAL,\n",
    "    Time_to_Max REAL,\n",
    "    Creation_Date TEXT,\n",
    "    FOREIGN KEY (Participant_ID) REFERENCES Participant(Participant_ID)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS IR90 (\n",
    "    Trial_ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Name TEXT,\n",
    "    Participant_ID INTEGER,\n",
    "    Avg_Force REAL,\n",
    "    Avg_Force_Norm REAL,\n",
    "    Max_Force REAL,\n",
    "    Max_Force_Norm REAL,\n",
    "    Time_to_Max REAL,\n",
    "    Creation_Date TEXT,\n",
    "    FOREIGN KEY (Participant_ID) REFERENCES Participant(Participant_ID)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS CMJ (\n",
    "    Trial_ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Name TEXT,\n",
    "    Participant_ID INTEGER,\n",
    "    Jump_Height REAL,\n",
    "    Peak_Power REAL,\n",
    "    Peak_Force REAL,\n",
    "    Creation_Date TEXT,\n",
    "    FOREIGN KEY (Participant_ID) REFERENCES Participant(Participant_ID)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS PPU (\n",
    "    Trial_ID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    Name TEXT,\n",
    "    Participant_ID INTEGER,\n",
    "    Jump_Height REAL,\n",
    "    Peak_Power REAL,\n",
    "    Peak_Force REAL,\n",
    "    Creation_Date TEXT,\n",
    "    FOREIGN KEY (Participant_ID) REFERENCES Participant(Participant_ID)\n",
    ");\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Prompt user to select a folder\n",
    "# -------------------------------------------------\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "selected_folder = filedialog.askdirectory(initialdir='D:/Readiness Screen 3/Data/')\n",
    "\n",
    "if not selected_folder:\n",
    "    print(\"No folder selected. Exiting...\")\n",
    "    exit()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. Locate the XML file (assuming 'sessionXYZ.xml')\n",
    "# -------------------------------------------------\n",
    "xml_file_path = ''\n",
    "for root_dir, _, files in os.walk(selected_folder):\n",
    "    for file in files:\n",
    "        if file.lower().startswith('session') and file.lower().endswith('.xml'):\n",
    "            xml_file_path = os.path.join(root_dir, file)\n",
    "            break\n",
    "    if xml_file_path:\n",
    "        break\n",
    "\n",
    "if not xml_file_path:\n",
    "    print(\"No XML file found. Exiting...\")\n",
    "    exit()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. Parse the XML file\n",
    "# -------------------------------------------------\n",
    "tree = ET.parse(xml_file_path)\n",
    "xml_root = tree.getroot()\n",
    "\n",
    "def find_text(element, tag):\n",
    "    found = element.find(tag)\n",
    "    return found.text if found is not None else None\n",
    "\n",
    "session_fields = xml_root.find(\".//Session/Fields\")\n",
    "name = find_text(session_fields, \"Name\")\n",
    "height = find_text(session_fields, \"Height\")\n",
    "weight = find_text(session_fields, \"Weight\")\n",
    "plyo_day = find_text(session_fields, \"Plyo_Day\")\n",
    "creation_date = find_text(session_fields, \"Creation_date\")\n",
    "\n",
    "if None in [name, height, weight, plyo_day, creation_date]:\n",
    "    print(\"Missing data in XML file. Exiting...\")\n",
    "    exit()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 5. Insert participant data\n",
    "# -------------------------------------------------\n",
    "cursor.execute(\"\"\"\n",
    "INSERT INTO Participant (Name, Height, Weight, Plyo_Day, Creation_Date)\n",
    "VALUES (?, ?, ?, ?, ?)\n",
    "\"\"\", (name, height, weight, plyo_day, creation_date))\n",
    "\n",
    "participant_id = cursor.lastrowid\n",
    "conn.commit()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 6. Define ASCII file mapping and output path\n",
    "# -------------------------------------------------\n",
    "ascii_files = {\n",
    "    \"I\": \"i_data.txt\",\n",
    "    \"Y\": \"y_data.txt\",\n",
    "    \"T\": \"t_data.txt\",\n",
    "    \"IR90\": \"ir90_data.txt\",\n",
    "    \"CMJ\": \"cmj_data.txt\",\n",
    "    \"PPU\": \"ppu_data.txt\"\n",
    "}\n",
    "output_path = 'D:/Readiness Screen 3/Output Files/'\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 7. Process files in the ASCII file dictionary\n",
    "# -------------------------------------------------\n",
    "for file_key, file_name in ascii_files.items():\n",
    "    file_path = os.path.join(output_path, file_name)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        \n",
    "        try:\n",
    "            # Depending on table, parse the correct columns \n",
    "            # WITHOUT reading creation_date from the .txt\n",
    "            if file_key in [\"I\", \"Y\", \"T\", \"IR90\"]:\n",
    "                # The text file columns: Max_Force, Max_Force_Norm, Avg_Force, Avg_Force_Norm, Time_to_Max\n",
    "                headers = [\"Max_Force\", \"Max_Force_Norm\", \"Avg_Force\", \"Avg_Force_Norm\", \"Time_to_Max\"]\n",
    "                df = pd.read_csv(file_path, sep='\\s+', skiprows=5, names=headers)\n",
    "\n",
    "            elif file_key in [\"CMJ\", \"PPU\"]:\n",
    "                # The text file columns: JH_IN, LEWIS_PEAK_POWER, Max_Force\n",
    "                headers = [\"JH_IN\", \"LEWIS_PEAK_POWER\", \"Max_Force\"]\n",
    "                df = pd.read_csv(file_path, sep='\\s+', skiprows=5, names=headers)\n",
    "\n",
    "            # Print a preview for debugging\n",
    "            print(f\"Data from {file_name} (first 5 rows):\")\n",
    "            print(df.head())\n",
    "\n",
    "            # Insert data into the database\n",
    "            table_name = file_key.upper()  # e.g., \"I\", \"Y\", etc.\n",
    "            \n",
    "            # Insert each row, attaching the same XML creation_date\n",
    "            for _, row in df.iterrows():\n",
    "                if file_key in [\"I\", \"Y\", \"T\", \"IR90\"]:\n",
    "                    cursor.execute(f\"\"\"\n",
    "                        INSERT INTO {table_name}\n",
    "                        (Name, Participant_ID, Avg_Force, Avg_Force_Norm, Max_Force, Max_Force_Norm, Time_to_Max, Creation_Date)\n",
    "                        VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
    "                    \"\"\", (\n",
    "                        name,\n",
    "                        participant_id,\n",
    "                        row['Avg_Force'],\n",
    "                        row['Avg_Force_Norm'],\n",
    "                        row['Max_Force'],\n",
    "                        row['Max_Force_Norm'],\n",
    "                        row['Time_to_Max'],\n",
    "                        creation_date    # from the XML\n",
    "                    ))\n",
    "\n",
    "                elif file_key in [\"CMJ\", \"PPU\"]:\n",
    "                    cursor.execute(f\"\"\"\n",
    "                        INSERT INTO {table_name}\n",
    "                        (Name, Participant_ID, Jump_Height, Peak_Power, Peak_Force, Creation_Date)\n",
    "                        VALUES (?, ?, ?, ?, ?, ?)\n",
    "                    \"\"\", (\n",
    "                        name,\n",
    "                        participant_id,\n",
    "                        row['JH_IN'],\n",
    "                        row['LEWIS_PEAK_POWER'],\n",
    "                        row['Max_Force'],\n",
    "                        creation_date    # from the XML\n",
    "                    ))\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {e}\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 8. Final Commit and Close\n",
    "# -------------------------------------------------\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Data successfully added to the database.\")\n"
   ],
   "id": "c2e807c2d7be32a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: D:/Readiness Screen 3/Output Files/i_data.txt\n",
      "Data from i_data.txt (first 5 rows):\n",
      "   Max_Force  Max_Force_Norm  Avg_Force  Avg_Force_Norm  Time_to_Max\n",
      "1      158.2           158.2      124.6          124.56         1.65\n",
      "Processing file: D:/Readiness Screen 3/Output Files/y_data.txt\n",
      "Data from y_data.txt (first 5 rows):\n",
      "   Max_Force  Max_Force_Norm  Avg_Force  Avg_Force_Norm  Time_to_Max\n",
      "1      131.5           131.5      111.3          111.32         3.02\n",
      "Processing file: D:/Readiness Screen 3/Output Files/t_data.txt\n",
      "Data from t_data.txt (first 5 rows):\n",
      "   Max_Force  Max_Force_Norm  Avg_Force  Avg_Force_Norm  Time_to_Max\n",
      "1      113.9           113.9       96.3           96.32         2.05\n",
      "Processing file: D:/Readiness Screen 3/Output Files/ir90_data.txt\n",
      "Data from ir90_data.txt (first 5 rows):\n",
      "   Max_Force  Max_Force_Norm  Avg_Force  Avg_Force_Norm  Time_to_Max\n",
      "1      152.8           152.8      127.5          127.48         2.45\n",
      "Processing file: D:/Readiness Screen 3/Output Files/cmj_data.txt\n",
      "Data from cmj_data.txt (first 5 rows):\n",
      "   JH_IN  LEWIS_PEAK_POWER  Max_Force\n",
      "1  19.16           4870.66    5713.79\n",
      "Processing file: D:/Readiness Screen 3/Output Files/ppu_data.txt\n",
      "Data from ppu_data.txt (first 5 rows):\n",
      "   JH_IN  LEWIS_PEAK_POWER  Max_Force\n",
      "1   3.88           2467.35     2668.5\n",
      "Data successfully added to the database.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T15:32:37.211612Z",
     "start_time": "2025-06-10T15:32:36.816477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reorders the database to be in alphabetical order\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "db_path = \"D:/Readiness Screen 3/Readiness_Screen_Data.db\" \n",
    "sort_column = \"Name\"     \n",
    "\n",
    "def reorder_all_tables(db_path, sort_column):\n",
    "    try:\n",
    "        # Connect to the database\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Fetch all table names in the database\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        tables = cursor.fetchall()\n",
    "\n",
    "        for table in tables:\n",
    "            table_name = table[0]\n",
    "\n",
    "            # Skip system tables like sqlite_sequence\n",
    "            if table_name.startswith(\"sqlite_\"):\n",
    "                continue\n",
    "\n",
    "            print(f\"Processing table: {table_name}\")\n",
    "\n",
    "            # Check if the column exists in the current table\n",
    "            cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "            columns = [info[1] for info in cursor.fetchall()]\n",
    "            if sort_column not in columns:\n",
    "                print(f\"Skipping table '{table_name}' - Column '{sort_column}' not found.\")\n",
    "                continue\n",
    "\n",
    "            # Create a new sorted table\n",
    "            temp_table = f\"{table_name}_sorted\"\n",
    "            cursor.execute(f\"CREATE TABLE {temp_table} AS SELECT * FROM {table_name} ORDER BY {sort_column} ASC;\")\n",
    "            \n",
    "            # Drop the old table\n",
    "            cursor.execute(f\"DROP TABLE {table_name};\")\n",
    "            \n",
    "            # Rename the new table to the original name\n",
    "            cursor.execute(f\"ALTER TABLE {temp_table} RENAME TO {table_name};\")\n",
    "            print(f\"Table '{table_name}' reordered successfully.\")\n",
    "\n",
    "        # Commit changes\n",
    "        conn.commit()\n",
    "        print(\"All tables processed.\")\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "reorder_all_tables(db_path, sort_column)\n"
   ],
   "id": "b88ed19b32a83688",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table: Participant\n",
      "Table 'Participant' reordered successfully.\n",
      "Processing table: I\n",
      "Table 'I' reordered successfully.\n",
      "Processing table: Y\n",
      "Table 'Y' reordered successfully.\n",
      "Processing table: T\n",
      "Table 'T' reordered successfully.\n",
      "Processing table: IR90\n",
      "Table 'IR90' reordered successfully.\n",
      "Processing table: CMJ\n",
      "Table 'CMJ' reordered successfully.\n",
      "Processing table: PPU\n",
      "Table 'PPU' reordered successfully.\n",
      "All tables processed.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T15:32:37.668914Z",
     "start_time": "2025-06-10T15:32:37.213130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creates Dash Report\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ---------------------------\n",
    "# Step 1: Data Loading\n",
    "# ---------------------------\n",
    "\n",
    "conn = sqlite3.connect('D:/Readiness Screen 3/Readiness_Screen_Data.db')\n",
    "\n",
    "df_cmj = pd.read_sql_query(\"SELECT Name, Creation_Date, Jump_Height AS Jump_Height_CMJ FROM CMJ;\", conn)\n",
    "df_ppu = pd.read_sql_query(\"SELECT Name, Creation_Date, Jump_Height AS Jump_Height_PPU FROM PPU;\", conn)\n",
    "df_i = pd.read_sql_query(\"SELECT Name, Creation_Date, Avg_Force AS Avg_Force_I FROM I;\", conn)\n",
    "df_y = pd.read_sql_query(\"SELECT Name, Creation_Date, Avg_Force AS Avg_Force_Y FROM Y;\", conn)\n",
    "df_t = pd.read_sql_query(\"SELECT Name, Creation_Date, Avg_Force AS Avg_Force_T FROM T;\", conn)\n",
    "df_ir90 = pd.read_sql_query(\"SELECT Name, Creation_Date, Avg_Force AS Avg_Force_IR90 FROM IR90;\", conn)\n",
    "conn.close()\n",
    "\n",
    "df_merged = df_cmj.merge(df_ppu, on=[\"Name\", \"Creation_Date\"], how=\"outer\")\n",
    "df_merged = df_merged.merge(df_i, on=[\"Name\", \"Creation_Date\"], how=\"outer\")\n",
    "df_merged = df_merged.merge(df_y, on=[\"Name\", \"Creation_Date\"], how=\"outer\")\n",
    "df_merged = df_merged.merge(df_t, on=[\"Name\", \"Creation_Date\"], how=\"outer\")\n",
    "df_merged = df_merged.merge(df_ir90, on=[\"Name\", \"Creation_Date\"], how=\"outer\")\n",
    "\n",
    "df_merged['Creation_Date'] = pd.to_datetime(df_merged['Creation_Date'])\n",
    "\n",
    "df_merged = df_merged.sort_values(by=\"Creation_Date\")\n",
    "\n",
    "participants = df_merged['Name'].dropna().unique()\n",
    "\n",
    "# ---------------------------\n",
    "# Step 2: Initialize the Dash App\n",
    "# ---------------------------\n",
    "\n",
    "app = Dash(__name__)\n",
    "\n",
    "# ---------------------------\n",
    "# Step 3: Dash Layout\n",
    "# ---------------------------\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Participant Measurements Over Time\"),\n",
    "\n",
    "    html.Div([\n",
    "        html.Label(\"Select a Participant:\"),\n",
    "        dcc.Dropdown(\n",
    "            id='participant-dropdown',\n",
    "            options=[{'label': p, 'value': p} for p in participants],\n",
    "            value=participants[0] if len(participants) > 0 else None,\n",
    "            clearable=False\n",
    "        )\n",
    "    ], style={'width': '30%', 'display': 'inline-block'}),\n",
    "\n",
    "    dcc.Graph(id='measurements-graph'),\n",
    "    dcc.Graph(id='jump-heights-graph')  # New plot for CMJ and PPU\n",
    "])\n",
    "\n",
    "# ---------------------------\n",
    "# Step 4: Callbacks\n",
    "# ---------------------------\n",
    "\n",
    "@app.callback(\n",
    "    [Output('measurements-graph', 'figure'),\n",
    "     Output('jump-heights-graph', 'figure')],  # Updated callback for two plots\n",
    "    [Input('participant-dropdown', 'value')]\n",
    ")\n",
    "def update_graph(selected_participant):\n",
    "    dff = df_merged[df_merged['Name'] == selected_participant]\n",
    "\n",
    "    # First plot: Measurements over time\n",
    "    fig_measurements = go.Figure()\n",
    "    \n",
    "    if 'Avg_Force_I' in dff.columns and dff['Avg_Force_I'].notnull().any():\n",
    "        fig_measurements.add_trace(go.Scatter(\n",
    "            x=dff['Creation_Date'], y=dff['Avg_Force_I'], mode='lines+markers', name='Avg_Force_I'\n",
    "        ))\n",
    "\n",
    "    if 'Avg_Force_Y' in dff.columns and dff['Avg_Force_Y'].notnull().any():\n",
    "        fig_measurements.add_trace(go.Scatter(\n",
    "            x=dff['Creation_Date'], y=dff['Avg_Force_Y'], mode='lines+markers', name='Avg_Force_Y'\n",
    "        ))\n",
    "\n",
    "    if 'Avg_Force_T' in dff.columns and dff['Avg_Force_T'].notnull().any():\n",
    "        fig_measurements.add_trace(go.Scatter(\n",
    "            x=dff['Creation_Date'], y=dff['Avg_Force_T'], mode='lines+markers', name='Avg_Force_T'\n",
    "        ))\n",
    "\n",
    "    if 'Avg_Force_IR90' in dff.columns and dff['Avg_Force_IR90'].notnull().any():\n",
    "        fig_measurements.add_trace(go.Scatter(\n",
    "            x=dff['Creation_Date'], y=dff['Avg_Force_IR90'], mode='lines+markers', name='Avg_Force_IR90'\n",
    "        ))\n",
    "\n",
    "    fig_measurements.update_layout(\n",
    "        title=f\"Measurements Over Time for {selected_participant}\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Measurement Value\",\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "\n",
    "    # Second plot: Jump Heights (CMJ and PPU)\n",
    "    fig_jump_heights = go.Figure()\n",
    "\n",
    "    if 'Jump_Height_CMJ' in dff.columns and dff['Jump_Height_CMJ'].notnull().any():\n",
    "        fig_jump_heights.add_trace(go.Scatter(\n",
    "            x=dff['Creation_Date'], y=dff['Jump_Height_CMJ'], mode='lines+markers', name='Jump_Height_CMJ'\n",
    "        ))\n",
    "\n",
    "    if 'Jump_Height_PPU' in dff.columns and dff['Jump_Height_PPU'].notnull().any():\n",
    "        fig_jump_heights.add_trace(go.Scatter(\n",
    "            x=dff['Creation_Date'], y=dff['Jump_Height_PPU'], mode='lines+markers', name='Jump_Height_PPU'\n",
    "        ))\n",
    "\n",
    "    fig_jump_heights.update_layout(\n",
    "        title=f\"Jump Heights Over Time for {selected_participant}\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Jump Height (cm)\",\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "\n",
    "    return fig_measurements, fig_jump_heights\n",
    "\n",
    "# ---------------------------\n",
    "# Step 5: Run the App\n",
    "# ---------------------------\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ],
   "id": "ce92c1f9cb987e75",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x23a1b2d31d0>"
      ],
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T15:32:37.673895Z",
     "start_time": "2025-06-10T15:32:37.670382Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6c3d634aef76d6ba",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
